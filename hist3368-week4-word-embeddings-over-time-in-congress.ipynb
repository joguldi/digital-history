{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For citation information, please see the \"Source Information\" section listed in the associated README file: https://github.com/stephbuon/digital-history/tree/master/hist3368-week12-word-context-vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hist 3368 - Week 4: Word Context Vectors for Congress"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### By Jo Guldi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we'll learn some more basics of working with Python. We'll also use our newfound skills at \"running\" code in Jupyter to create some very intensive visualizations of how word usage has changed over time in Congress."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basics: loading software from elsewhere"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing new software packages\n",
    "\n",
    "Users of code often borrow software written by other people because it means taking a shortcut rather than reinventing the wheel.\n",
    "\n",
    "We will frequently 'import' software packages so that we can use commands and variables that other people have invented.\n",
    "\n",
    "In general, we will import software packages with the command 'import.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import wordnet as wn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the line of code above. If all goes well, you won't get an error message.  You'll just see a star (*) by the cell while the computer thinks for a moment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will need to 'import' a software package at the beginning of each session in which you use that package.  Most of our future notebooks will begin with a string of 'import' commands to set things up."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Installing new software packages\n",
    "\n",
    "The first time you use a new software package, that package first needs to be 'installed' on your part of the super computer.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To install a new software package, we need special punctuation that tells M2 that we want control over the settings of the supercomputer.  Here is the syntax to install a package called 'bs4.'  We used many commands of this kind in the first-time-setup notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gensim --upgrade --user # you only need to run this once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If any of the above 'import' commands failed to work, you can use the **!pip install xxx --user** syntax to install them  now. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Error messages that indicate installations/importing are needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will also get error messages if you try to use a command from a package that hasn't been installed or imported.  \n",
    "\n",
    "For example, here is a function that I made up:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "breakdance(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If breakdance were a legitimate function, seeing the 'NameError' next to a function would be a good sign that we need to try installing and importing a software package that defines the function 'breakdance().'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working With Word Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we're going to be calling some files called \"word embeddings\" that were generated by your professor and stored on M2. Word embeddings are multi-dimensional models of language over time.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading pre-generated word embeddings models\n",
    "\n",
    "The following line of code tells the computer to look in the course folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd /scratch/group/history/hist_3368-jguldi/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we tell the computer to load the pre-generated files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wv = KeyedVectors.load(\"word2vec.wordvectors\", mmap='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calling the model to investigate words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the word embeddings model loaded, we can use the commands 'wv(word)' (word vector) and 'wv.similar_by_vector(word, n)' to call the words are 'similar' in terms of the model's understanding of speech.\n",
    "\n",
    "With  'wv(word)' and 'wv.similar_by_vector(word_vector, n)', the user can switch out the \"word\" for any word spoken in English.  You can switch out n for any number.  That number of words will be returned.\n",
    "\n",
    "Note that the output is a list of words that were commonly used alongside the word \"man.\"  Each word is paired with a number, which represents ths \"similarity score\" of how frequently that word or phrase appears with the word \"man.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "man_vector = wv['man']\n",
    "wv.similar_by_vector(man_vector, 25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore the Contents of Your Vector Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please note that in this exercise, you are less interested in learning every single command than you are in \"playing\" with the model to understand what it is telling you about speech in Congress."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find the CONTEXT for One Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "woman_vector = wv['woman']\n",
    "wv.similar_by_vector(woman_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "individual_vector = wv['person']\n",
    "wv.similar_by_vector(individual_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soldier_vector = wv['soldier']\n",
    "wv.similar_by_vector(soldier_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpreting vector similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try your own hand at interpreting these outputs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do you interpret these similarities?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wv.most_similar(\"iraq\", topn = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wv.most_similar(\"america\", topn = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wv.most_similar(\"britain\", topn = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subtracting Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = wv['man'] - wv['woman']\n",
    "wv.similar_by_vector(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = wv['woman'] - wv['boy']\n",
    "wv.similar_by_vector(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = wv['people'] - wv['person']\n",
    "wv.similar_by_vector(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = wv['person'] - wv['people']\n",
    "wv.similar_by_vector(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = wv['think'] - wv['heart']\n",
    "wv.similar_by_vector(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = wv['feel'] - wv['think']\n",
    "wv.similar_by_vector(diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding vectors to find synonyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_context = [word[0] for word in wv.most_similar(\"woman\", topn = 100)]\n",
    "\n",
    "sum = wv[keyword_context[0]] \n",
    "\n",
    "for word in keyword_context[1:len(keyword_context)]:\n",
    "    next_vector = wv[word] \n",
    "    sum = sum + next_vector\n",
    "    \n",
    "wv.similar_by_vector(sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_context = [word[0] for word in wv.most_similar(\"soldier\", topn = 100)]\n",
    "sum = wv[keyword_context[0]] \n",
    "for word in keyword_context[1:len(keyword_context)]:\n",
    "    next_vector = wv[word] \n",
    "    sum = sum + next_vector\n",
    "wv.similar_by_vector(sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_context = [word[0] for word in wv.most_similar(\"happy\", topn = 100)]\n",
    "sum = wv[keyword_context[0]] \n",
    "for word in keyword_context[1:len(keyword_context)]:\n",
    "    next_vector = wv[word] \n",
    "    sum = sum + next_vector\n",
    "wv.similar_by_vector(sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_context = [word[0] for word in wv.most_similar(\"american\", topn = 100)]\n",
    "sum = wv[keyword_context[0]] \n",
    "for word in keyword_context[1:len(keyword_context)]:\n",
    "    next_vector = wv[word] \n",
    "    sum = sum + next_vector\n",
    "wv.similar_by_vector(sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distance and Similarity with Vectors in GENSIM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With similarity, the higher the number, the more alike two terms are in the context in which they are used. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wv.similarity('woman', 'female')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wv.similarity('woman', 'man')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wv.similarity('soldier', 'man')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wv.similarity('woman', 'person')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wv.similarity('woman', 'rock')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize the similarities as a Dendrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = ['dream',  'war',  'wealth', 'happy',  'tomorrow', 'past', 'present', 'future', 'america', 'democracy', 'riot', 'dictator', 'money', 'oppression', 'prison',  'britain', 'china', 'democrat', 'republican', 'welfare', 'communism', 'russia', 'congress', 'protest']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_vectors = wv[keywords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "links = linkage(keyword_vectors, method='complete', metric='seuclidean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "l = links\n",
    "\n",
    "# calculate full dendrogram\n",
    "plt.figure(figsize=(25, 10))\n",
    "plt.title('Hierarchical Clustering Dendrogram')\n",
    "plt.ylabel('word')\n",
    "plt.xlabel('distance')\n",
    "\n",
    "dendrogram(\n",
    "    l,\n",
    "    leaf_rotation=0,  # rotates the x axis labels\n",
    "    leaf_font_size=16,  # font size for the x axis labels\n",
    "    orientation='left',\n",
    "    leaf_label_func=lambda v: str(keywords[v])\n",
    ")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note: if you get an error above, delete any words from the list.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing Abstract Relatedness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from gensim.test.utils import datapath, get_tmpfile\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib inline\n",
    "\n",
    "def display_pca_scatterplot(model, words=None, sample=0):\n",
    "    if words == None:\n",
    "        if sample > 0:\n",
    "            words = np.random.choice(list(model.wv.key_to_index.keys()), sample)\n",
    "        else:\n",
    "            words = [ word for word in model.wv.key_to_index ]\n",
    "        \n",
    "    word_vectors = np.array([model[w] for w in words])\n",
    "\n",
    "    twodim = PCA().fit_transform(word_vectors)[:,:2]\n",
    "    \n",
    "    plt.figure(figsize=(6,6))\n",
    "    plt.scatter(twodim[:,0], twodim[:,1], edgecolors='k', c='r')\n",
    "    for word, (x,y) in zip(words, twodim):\n",
    "        plt.text(x+0.05, y+0.05, word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_pca_scatterplot(wv, keywords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Study change over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd '/scratch/group/history/hist_3368-jguldi/congress-embeddings'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataname = 'lemmatized-stopworded-bigrammed-congress-model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword1 = 'woman'  # the word you want to research"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "periodnames = []\n",
    "for i in range(1870,2010, 5):\n",
    "    periodnames.append(i) \n",
    "periodnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########  after the first run, use this line to call the old data without generating it again\n",
    "keyword_context = []\n",
    "dates_found = []\n",
    "\n",
    "# cycle through each period\n",
    "for period1 in periodnames:\n",
    "    print('working on ', period1)\n",
    "    \n",
    "    # load the model from period1\n",
    "    #period_model = gensim.models.Word2Vec.load(dataname + '-model-' + str(period1)) # to load a saved model\n",
    "    period_wv = KeyedVectors.load(dataname + '--wv-model-' + str(period1)) # load the saved model\n",
    "    \n",
    "    ## is the keyword found?\n",
    "    if keyword1 in period_wv.key_to_index:\n",
    "        print('found ', keyword1)\n",
    "        \n",
    "        # get the context vector for keyword1\n",
    "        keyword_context_period = period_wv.most_similar(keyword1, topn = 5000) \n",
    "        \n",
    "        # save it for later\n",
    "        keyword_context.append(keyword_context_period) # save the context of how women were talked about for later\n",
    "        dates_found.append(period1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to abstract only unique values while keeping the list in the same order -- the order of first appearance\n",
    "def unique2(seq):\n",
    "    seen = set()\n",
    "    seen_add = seen.add\n",
    "    return [x for x in seq if not (x in seen or seen_add(x))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = []\n",
    "for i in range(len(dates_found)):\n",
    "    words = [item[0] for item in keyword_context[i]][:10]\n",
    "    all_words.append(words)\n",
    "\n",
    "all_words2 = []\n",
    "for list in all_words:\n",
    "    for word in list:\n",
    "        all_words2.append(word)\n",
    "\n",
    "numwords = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd ~/ # go to your home directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "#from matplotlib.colors import ListedColormap, LinearSegmentedColormap\n",
    "\n",
    "from adjustText import adjust_text\n",
    "from numpy import linspace\n",
    "from matplotlib import cm\n",
    "\n",
    "colors = [ cm.viridis(x) for x in linspace(0, 1, len(unique2(all_words2))+10) ]\n",
    "\n",
    "# change the figure's size here\n",
    "plt.figure(figsize=(20,20), dpi = 300)\n",
    "\n",
    "texts = []\n",
    "\n",
    "# plt.annotate only plots one label per iteration, so we have to use a for loop \n",
    "for i in range(len(dates_found)):    # cycle through the period names\n",
    "    \n",
    "    #yyy = int(keyword_per_year[keyword_per_year['5yrperiod'] == int(xx)]['count'])   # how many times was the keyword used that year?\n",
    "                     \n",
    "    for j in range(5):     # cycle through the first ten words (you can change this variable)\n",
    "        \n",
    "        xx = dates_found[i]        # on the x axis, plot the period name\n",
    "        yy = [item[1] for item in keyword_context[i]][j]         # on the y axis, plot the distance -- how closely the word is related to the keyword\n",
    "        txt = [item[0] for item in keyword_context[i]][j]        # grab the name of each collocated word\n",
    "        colorindex = unique2(all_words2).index(txt)   # this command keeps all dots for the same word the same color\n",
    "        \n",
    "        plt.scatter(                                             # plot dots\n",
    "            xx, #x axis\n",
    "            yy, # y axis\n",
    "            linewidth=1, \n",
    "            color = colors[colorindex],\n",
    "            edgecolors = 'darkgray',\n",
    "            s = 100, # dot size\n",
    "            alpha=0.8)  # dot transparency\n",
    "\n",
    "        # make a label for each word\n",
    "        texts.append(plt.text(xx, yy, txt))\n",
    "\n",
    "# Code to help with overlapping labels -- may take a minute to run\n",
    "adjust_text(texts, force_points=0.2, force_text=.7, \n",
    "                    expand_points=(1, 1), expand_text=(1, 1),\n",
    "                    arrowprops=dict(arrowstyle=\"-\", color='black', lw=0.5))\n",
    "\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "# Add titles\n",
    "plt.title(\"What words were most similar to ''\" + keyword1 + \"' in Congress?\", fontsize=20, fontweight=0, color='Red')\n",
    "plt.xlabel(\"period\")\n",
    "plt.ylabel(\"similarity to \" + keyword1)\n",
    "\n",
    "\n",
    "filename = 'words-similar-to-' + keyword1 + '-' + dataname\n",
    "plt.savefig(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
